{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_Classification_최종.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPzlEpwt03xnKtMDSxgEPnx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f93edd7f863842dab7e1e51883177c66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56b209d6b441498e93ee886f880b6d4a","IPY_MODEL_b3ba1f9207cd4dd3935b239b772a8e2c","IPY_MODEL_7abee6b8c26b48549c519987a45c1c56"],"layout":"IPY_MODEL_d635f6413c444fcdb1cf5c0d85775e60"}},"56b209d6b441498e93ee886f880b6d4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e169e465a06e4f769d2eec665eb5d574","placeholder":"​","style":"IPY_MODEL_387cdfacbf82411a8dfcb80a55a855a3","value":"Downloading: 100%"}},"b3ba1f9207cd4dd3935b239b772a8e2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9670d6100091464f8b7ae86854fb6b4c","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b25a6c50877f44bdb148d683317ce2fa","value":440473133}},"7abee6b8c26b48549c519987a45c1c56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00e6d492d14540c8867264fee8432757","placeholder":"​","style":"IPY_MODEL_66ef61fad5404af4af520c3288147711","value":" 420M/420M [00:07&lt;00:00, 58.6MB/s]"}},"d635f6413c444fcdb1cf5c0d85775e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e169e465a06e4f769d2eec665eb5d574":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"387cdfacbf82411a8dfcb80a55a855a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9670d6100091464f8b7ae86854fb6b4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25a6c50877f44bdb148d683317ce2fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00e6d492d14540c8867264fee8432757":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ef61fad5404af4af520c3288147711":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 라이브러리"],"metadata":{"id":"zPWVD9OHtH28"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aTkOfr3t2mx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647504183225,"user_tz":-540,"elapsed":8426,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"48bcea6e-7bad-448c-b0f0-17854336bd55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 12.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 67.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 77.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["pip install transformers"]},{"cell_type":"code","source":["import os\n","import pdb\n","# import wandb\n","import argparse\n","import pandas as pd\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from collections import defaultdict\n","\n","import torch\n","from torch.optim import Adam, AdamW\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n","\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    BertTokenizerFast,\n","    get_linear_schedule_with_warmup,\n","    get_cosine_schedule_with_warmup,\n","    AutoConfig\n","    )\n","\n","import gc"],"metadata":{"id":"D_lI6d7I20rS","executionInfo":{"status":"ok","timestamp":1647504969626,"user_tz":-540,"elapsed":413,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0wkEcRY20uy","executionInfo":{"status":"ok","timestamp":1647504229989,"user_tz":-540,"elapsed":38337,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"outputId":"6010d2bf-93cf-4865-c870-b40124c0e23d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"metadata":{"id":"Own2N6-t3-Tq","executionInfo":{"status":"ok","timestamp":1647504229990,"user_tz":-540,"elapsed":8,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# data load\n","def make_data_strings(file_name):\n","        data_strings = []\n","        with open(os.path.join('/gdrive/MyDrive/goorm/01. text_classification/datas', file_name), 'r', encoding='utf-8') as f:\n","            id_file_data = [line.lower().rstrip() for line in f.readlines()]\n","        return id_file_data\n","\n","train_pos = make_data_strings('sentiment.train.1')\n","train_neg = make_data_strings('sentiment.train.0')\n","dev_pos = make_data_strings('sentiment.dev.1')\n","dev_neg = make_data_strings('sentiment.dev.0')"],"metadata":{"id":"HUl7QYgR484g","executionInfo":{"status":"ok","timestamp":1647504285179,"user_tz":-540,"elapsed":1408,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_pos_label = [1 for i in train_pos]\n","train_neg_label = [0 for i in train_neg]\n","train_label = train_pos_label + train_neg_label\n","\n","dev_pos_label = [1 for i in dev_pos]\n","dev_neg_label = [0 for i in dev_neg]\n","dev_label = dev_pos_label + dev_neg_label\n","\n","train_data = train_pos + train_neg\n","dev_data = dev_pos + dev_neg"],"metadata":{"id":"MFjTkant5FjL","executionInfo":{"status":"ok","timestamp":1647504777202,"user_tz":-540,"elapsed":3,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["path = 'bert-base-uncased'\n","\n","tokenizer = BertTokenizerFast.from_pretrained(path)\n","model = BertForSequenceClassification.from_pretrained(path)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)"],"metadata":{"id":"U5U8LoKl5XkR","executionInfo":{"status":"ok","timestamp":1647504377564,"user_tz":-540,"elapsed":25171,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"colab":{"base_uri":"https://localhost:8080/","height":163,"referenced_widgets":["f93edd7f863842dab7e1e51883177c66","56b209d6b441498e93ee886f880b6d4a","b3ba1f9207cd4dd3935b239b772a8e2c","7abee6b8c26b48549c519987a45c1c56","d635f6413c444fcdb1cf5c0d85775e60","e169e465a06e4f769d2eec665eb5d574","387cdfacbf82411a8dfcb80a55a855a3","9670d6100091464f8b7ae86854fb6b4c","b25a6c50877f44bdb148d683317ce2fa","00e6d492d14540c8867264fee8432757","66ef61fad5404af4af520c3288147711"]},"outputId":"ab83d68a-e15f-4d23-bd30-f9272ddfc42c"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93edd7f863842dab7e1e51883177c66"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def preprocess(text_data, label_data, batch_size=64):\n","    batch_input = tokenizer(text_data, truncation=True, padding=True)\n","\n","    batch_input = {key : torch.tensor(value) for key, value in batch_input.items()}\n","\n","    label = torch.tensor((label_data))\n","\n","    dataset = TensorDataset(\n","        batch_input['input_ids'], \n","        batch_input['token_type_ids'],\n","        batch_input['attention_mask'], \n","        label)\n","    \n","    dataset_sampler = RandomSampler(dataset)\n","    dataset = DataLoader(dataset, sampler = dataset_sampler, batch_size= batch_size)\n","\n","    return dataset          "],"metadata":{"id":"iDu0Xjaj5YcL","executionInfo":{"status":"ok","timestamp":1647504474673,"user_tz":-540,"elapsed":344,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_dataloader = preprocess(train_data, train_label,batch_size=128)\n","dev_dataloader = preprocess(dev_data, dev_label,batch_size=128)"],"metadata":{"id":"6UoCZKE85fka","executionInfo":{"status":"ok","timestamp":1647504997797,"user_tz":-540,"elapsed":16595,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습"],"metadata":{"id":"RhxOuMpotAB_"}},{"cell_type":"code","source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"x7IUt2AZ65qu","executionInfo":{"status":"ok","timestamp":1647504850235,"user_tz":-540,"elapsed":414,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["save_path = 'bert_classification'\n","train_epoch = 4\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# param_optimizer = list(model.named_parameters())\n","# no_decay = ['bias', 'gamma', 'beta']\n","# optimizer_grouped_parameters = [\n","#     {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","#     'weight_decay_rate': 0.01},\n","#     {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","#     'weight_decay_rate': 0.0}\n","# ]\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n","\n","total_steps = len(train_dataloader) * train_epoch\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","for epoch in range(train_epoch):\n","# =====================================\n","#               Training\n","# =====================================\n","    model.train()\n","\n","    train_loss = 0.0\n","\n","    for batchs in tqdm(train_dataloader):\n","        batch = tuple(b.to(device) for b in batchs)\n","\n","        l_input_ids, l_segment, l_mask, l_labels = batch\n","\n","        optimizer.zero_grad()\n","\n","        output = model(l_input_ids,\n","                        token_type_ids = l_segment if len(torch.unique(l_segment.flatten())) > 1 else None,\n","                        attention_mask=l_mask,\n","                        labels=l_labels)\n","        \n","        loss = output[0]\n","        \n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_dataloader)\n","    print(f'epoch - {epoch} Train_Loss : ', avg_train_loss)\n","\n","# =====================================\n","#               Evaluation\n","# =====================================\n","            \n","    model.eval()\n","\n","    eval_loss, eval_accuracy = 0, 0\n","\n","\n","    for batchs in tqdm(dev_dataloader):\n","        batch = tuple(b.to(device) for b in batchs)\n","        l_input_ids, l_segment, l_mask, l_labels = batch\n","\n","        with torch.no_grad():\n","             output = model(l_input_ids,\n","                            token_type_ids = l_segment if len(torch.unique(l_segment.flatten())) > 1 else None,\n","                            attention_mask=l_mask)\n","                \n","        logits = output[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = l_labels.to('cpu').numpy()\n","\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","\n","    avg_accuracy = eval_accuracy/len(dev_dataloader)\n","    print(avg_accuracy)\n","\n","    model.save_pretrained(f'/gdrive/MyDrive/goorm/01. text_classification/models/{save_path}')"],"metadata":{"id":"fnQqFBN7_Yfs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 테스트"],"metadata":{"id":"3OXhxqqu_2jY"}},{"cell_type":"code","source":["save_path = 'bert_classification'\n","model = BertForSequenceClassification.from_pretrained(f'/gdrive/MyDrive/goorm/01. text_classification/models/{save_path}')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)"],"metadata":{"id":"PHSLrQLJ_yvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = pd.read_csv('/gdrive/MyDrive/goorm/01. text_classification/datas/test_no_label.csv')\n","\n","test_batch_input = tokenizer(test_df['Id'].tolist(), truncation=True, padding=True)\n","test_batch_input = {key : torch.tensor(value) for key, value in test_batch_input.items()}\n","\n","test_dataset = TensorDataset(test_batch_input['input_ids'],test_batch_input['attention_mask'])\n","test_dataset = DataLoader(test_dataset,  batch_size= 128)"],"metadata":{"id":"_RRd5sGdBr7S","executionInfo":{"status":"ok","timestamp":1647506329165,"user_tz":-540,"elapsed":412,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","\n","pred = []\n","for batchs in tqdm(test_dataset):\n","    batch = tuple(b.to(device) for b in batchs)\n","    l_input_ids, l_mask = batch\n","\n","    with torch.no_grad():\n","            output = model(l_input_ids,\n","                        token_type_ids = l_segment if len(torch.unique(l_segment.flatten())) > 1 else None,\n","                        attention_mask=l_mask)\n","            \n","    logits = output[0].detach().cpu()\n","    pred.append(logits)\n","\n","preds = torch.cat(pred, dim=0)\n","predictions = np.argmax(preds, axis=1)"],"metadata":{"id":"qwP_vglF_--y","executionInfo":{"status":"ok","timestamp":1647506469712,"user_tz":-540,"elapsed":1122,"user":{"displayName":"박정호","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggmkpfk7ypFS-awqdcEb0eV-KsaPVpj6ru8vni6rQ=s64","userId":"04165485851555310341"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa75e558-b7ff-49a4-b41e-73a75ce72895"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 20.13it/s]\n"]}]},{"cell_type":"code","source":["test_df['Category'] = predictions\n","\n","test_df.to_csv('/gdrive/My Drive/goorm/text_classification/submission.csv', index=False)"],"metadata":{"id":"Z2ttNBErAHbW"},"execution_count":null,"outputs":[]}]}